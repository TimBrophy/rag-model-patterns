# Elasticsearch details
elastic_url = '<your cluster url>'
kibana_url = '<your kibana url>'
elastic_api_key = '<your elastic api key>'

# leave these as-is
default_index = 'search-reports'
default_pipeline = 'ml-inference-search-reports'
transformer_model = '.elser_model_2_linux-x86_64'
logging_index = 'llm-log'
logging_pipeline = 'ml-inference-llm-log'
benchmarking_index = 'benchmarking'
benchmarking_results_index = 'benchmarking-results'

# Azure OpenAI details
openai_api_key = '<your azure openai api key>'
openai_api_type = 'azure'
openai_api_base = '<your azure openai deployment base url>'
openai_api_version = '<your model version>'
openai_api_model = '<your model name>'
deployment_name = "<your chat model deployment name>"
openai_embedding_deployment = '<your embeddings model deployment name>'
openai_embedding_model = '<your embedding model version>'

# AWS Bedrock details
aws_access_key='<your aws access key>'
aws_secret_key='<your aws secret key>'
aws_region='<your aws region>'
aws_model_id='a<your aws chat model>'