# Elasticsearch details
elastic_url = '<your cluster url>'
kibana_url = '<your kibana url>'
elastic_api_key = '<your elastic api key>'

# leave these as-is
default_index = 'search-reports'
default_pipeline = 'ml-inference-search-reports'
transformer_model = '.elser_model_2_linux-x86_64'
logging_index = 'llm-log'
logging_pipeline = 'ml-inference-llm-log'
benchmarking_index = 'benchmarking'
benchmarking_results_index = 'benchmarking-results'

# Azure OpenAI details
openai_api_key = '<your azure openai api key>'
openai_api_type = 'azure'
openai_api_base = '<your azure openai deployment base url>'
openai_api_version = '<your model version>'
openai_api_model = '<your model name>'
deployment_name = "<your chat model deployment name>"

# AWS Bedrock details
aws_access_key='<your aws access key>'
aws_secret_key='<your aws secret key>'
aws_region='<your aws region>'
aws_model_id='a<your aws chat model>'

# Ollama details
ollama_chat_model = '<your model name>'

# Ragas evaluation model details
evaluation_llm_provider = '<the model you are choosing to use for evaluation>'

evaluation_embedding_provider = '<the provider you are choosing to use for the evaluation embedding model>'
evaluation_embedding_model = ''<the model you are choosing to use for evaluation embedding>''
evaluation_embedding_model_deployment = '<the deployment name of the embedding model for evaluation>' (can be blank if you're using Ollama locally)